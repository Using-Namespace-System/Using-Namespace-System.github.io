{
    "version": "https://jsonfeed.org/version/1",
    "title": "Using-Namespace-System.github.io",
    "description": "",
    "home_page_url": "https://using-namespace-system.github.io",
    "feed_url": "https://using-namespace-system.github.io/feed.json",
    "user_comment": "",
    "icon": "https://using-namespace-system.github.io/media/website/Capture.PNG",
    "author": {
        "name": "Brian Recktenwall-Calvet"
    },
    "items": [
        {
            "id": "https://using-namespace-system.github.io/natural-language-processing-1-term-document-matrix.html",
            "url": "https://using-namespace-system.github.io/natural-language-processing-1-term-document-matrix.html",
            "title": "Natural Language Processing[1]: Term-Document Matrix",
            "summary": "This is the first in a series of posts on extracting word representations using statistical language modeling techniques. This first installment includes rudimentary corpus preprocessing, tokenization, and vectorization. The corpus is a public domain dataset of a million news headlines from the Australian Broadcasting Corporation&hellip;",
            "content_html": "<main>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">This is the first in a series of posts on extracting word representations using statistical language modeling techniques. This first installment includes rudimentary corpus preprocessing, tokenization, and vectorization. The corpus is a public domain dataset of a million news headlines from the Australian Broadcasting Corporation between 2003 and 2021.</span></div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<p>All code blocks are included in this document and the first block includes the imports used in this project.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\">In [ ]:</div>\n<div class=\"jp-CodeMirrorEditor jp-Editor jp-InputArea-editor\" data-type=\"inline\">\n<div class=\"cm-editor cm-s-jupyter\">\n<div class=\"highlight hl-ipython3\">\n<pre><span class=\"kn\">from</span> <span class=\"nn\">itertools</span> <span class=\"kn\">import</span> <span class=\"n\">zip_longest</span>\n<span class=\"kn\">from</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"kn\">import</span> <span class=\"n\">figure</span>\n<span class=\"kn\">import</span> <span class=\"nn\">nltk</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nltk.corpus</span> <span class=\"kn\">import</span> <span class=\"n\">stopwords</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scipy.sparse</span> <span class=\"kn\">import</span> <span class=\"n\">csr_array</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scipy.sparse</span> <span class=\"kn\">import</span> <span class=\"n\">find</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pickleshare</span> <span class=\"kn\">import</span> <span class=\"n\">PickleShareDB</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'../input/abcnews-date-text.csv'</span><span class=\"p\">)</span>\n<span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"s1\">'stopwords'</span><span class=\"p\">)</span>\n<span class=\"n\">stopwords_set</span> <span class=\"o\">=</span> <span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">stopwords</span><span class=\"o\">.</span><span class=\"n\">words</span><span class=\"p\">(</span><span class=\"s1\">'english'</span><span class=\"p\">))</span>\n</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\"> </div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<p>Preprocessing the corpus is simplified to filtering out short headlines, small words, and stop-words. Each action is completed in pandas, I believe this may improve readability. The documents are exploded into a single series representing the whole corpus from here stop-words can be filtered out. No further sanitation is performed.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\">In [ ]:</div>\n<div class=\"jp-CodeMirrorEditor jp-Editor jp-InputArea-editor\" data-type=\"inline\">\n<div class=\"cm-editor cm-s-jupyter\">\n<div class=\"highlight hl-ipython3\">\n<pre><span class=\"c1\">#tokenize and sanitize</span>\n\n<span class=\"c1\">#tokenize documents into individual words</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'tokenized'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">headline_text</span><span class=\"o\">.</span><span class=\"n\">str</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#remove short documents from corpus</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'length'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">)</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">length</span> <span class=\"o\">&gt;</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n\n<span class=\"c1\">#use random subset of corpus</span>\n<span class=\"c1\">#df=df.sample(frac=0.0016).reset_index()</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#flatten all words into single series</span>\n<span class=\"n\">ex</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">explode</span><span class=\"p\">(</span><span class=\"s1\">'tokenized'</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#remove shorter words</span>\n<span class=\"n\">ex</span> <span class=\"o\">=</span> <span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">str</span><span class=\"o\">.</span><span class=\"n\">len</span><span class=\"p\">()</span> <span class=\"o\">&gt;</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n\n<span class=\"c1\">#remove stop-words</span>\n<span class=\"n\">ex</span> <span class=\"o\">=</span> <span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"o\">~</span><span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">isin</span><span class=\"p\">(</span><span class=\"n\">stopwords_set</span><span class=\"p\">)]</span>\n</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\"> </div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<p>Tokenization of the corpus is performed by creating forward and backwards lookup dictionaries. Each unique word is represented as a unique number. This is a very simple method of tokenization.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\">In [ ]:</div>\n<div class=\"jp-CodeMirrorEditor jp-Editor jp-InputArea-editor\" data-type=\"inline\">\n<div class=\"cm-editor cm-s-jupyter\">\n<div class=\"highlight hl-ipython3\">\n<pre><span class=\"c1\">#create dictionary of words</span>\n\n<span class=\"c1\">#shuffle for sparse matrix visual</span>\n<span class=\"n\">dictionary</span> <span class=\"o\">=</span> <span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">drop_duplicates</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">frac</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#dataframe with (index/code):word</span>\n<span class=\"n\">dictionary</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">(</span><span class=\"n\">dictionary</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'words'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to_frame</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#store code:word dictionary for reverse encoding</span>\n<span class=\"n\">dictionary_lookup</span> <span class=\"o\">=</span> <span class=\"n\">dictionary</span><span class=\"o\">.</span><span class=\"n\">to_dict</span><span class=\"p\">()[</span><span class=\"s1\">'words'</span><span class=\"p\">]</span>\n\n<span class=\"c1\">#offset index to prevent clash with zero fill</span>\n<span class=\"n\">dictionary</span><span class=\"p\">[</span><span class=\"s1\">'encode'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">dictionary</span><span class=\"o\">.</span><span class=\"n\">index</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n\n<span class=\"c1\">#store word:code dictionary for encoding</span>\n<span class=\"n\">dictionary</span> <span class=\"o\">=</span> <span class=\"n\">dictionary</span><span class=\"o\">.</span><span class=\"n\">set_index</span><span class=\"p\">(</span><span class=\"s1\">'words'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to_dict</span><span class=\"p\">()[</span><span class=\"s1\">'encode'</span><span class=\"p\">]</span>\n\n<span class=\"c1\">#use dictionary to encode each word to integer representation</span>\n<span class=\"n\">encode</span> <span class=\"o\">=</span> <span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">dictionary</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to_frame</span><span class=\"p\">()</span>\n<span class=\"n\">encode</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">'int'</span><span class=\"p\">)</span>\n<span class=\"n\">encode</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">'int'</span><span class=\"p\">)</span>\n<span class=\"c1\">#un-flatten encoded words back into original documents</span>\n<span class=\"n\">docs</span> <span class=\"o\">=</span> <span class=\"n\">encode</span><span class=\"o\">.</span><span class=\"n\">tokenized</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">level</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">agg</span><span class=\"p\">(</span><span class=\"nb\">tuple</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#match up document indexes for reverse lookup</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">sort_index</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()</span>\n<span class=\"n\">docs</span> <span class=\"o\">=</span> <span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()[</span><span class=\"s1\">'tokenized'</span><span class=\"p\">]</span>\n</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\"> </div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<p>Vectorization here is done in its simplest form. The word vector for each term is the one-hot encoding of the documents they are and are not present in. The transform is comprised of document-word vectors where each is a one-hot encoding of the terms in the corpus that are and are not present in a document.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\">In [ ]:</div>\n<div class=\"jp-CodeMirrorEditor jp-Editor jp-InputArea-editor\" data-type=\"inline\">\n<div class=\"cm-editor cm-s-jupyter\">\n<div class=\"highlight hl-ipython3\">\n<pre><span class=\"c1\">#zero pad x dimension by longest sentence</span>\n<span class=\"n\">encoded_docs</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">zip_longest</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">docs</span><span class=\"o\">.</span><span class=\"n\">to_list</span><span class=\"p\">(),</span> <span class=\"n\">fillvalue</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)))</span>\n\n<span class=\"c1\">#convert to sparse matrix</span>\n<span class=\"n\">encoded_docs</span> <span class=\"o\">=</span> <span class=\"n\">csr_array</span><span class=\"p\">(</span><span class=\"n\">encoded_docs</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"nb\">int</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#convert to index for each word</span>\n<span class=\"n\">row_column_code</span> <span class=\"o\">=</span> <span class=\"n\">find</span><span class=\"p\">(</span><span class=\"n\">encoded_docs</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#presort by words</span>\n<span class=\"n\">word_sorted_index</span> <span class=\"o\">=</span> <span class=\"n\">row_column_code</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">argsort</span><span class=\"p\">()</span>\n<span class=\"n\">doc_word</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">row_column_code</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"n\">word_sorted_index</span><span class=\"p\">],</span> <span class=\"n\">row_column_code</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">][</span><span class=\"n\">word_sorted_index</span><span class=\"p\">]])</span>\n\n<span class=\"c1\">#presort by docs and words</span>\n<span class=\"n\">doc_word_sorted_index</span> <span class=\"o\">=</span> <span class=\"n\">doc_word</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">argsort</span><span class=\"p\">()</span>\n<span class=\"n\">doc_word</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"n\">doc_word</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"n\">doc_word_sorted_index</span><span class=\"p\">],</span> <span class=\"n\">doc_word</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"n\">doc_word_sorted_index</span><span class=\"p\">]])</span><span class=\"o\">.</span><span class=\"n\">T</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'doc'</span><span class=\"p\">,</span><span class=\"s1\">'word'</span><span class=\"p\">])</span>\n\n<span class=\"c1\">#offset code no longer needed after zero-fill</span>\n<span class=\"n\">doc_word</span><span class=\"o\">.</span><span class=\"n\">word</span> <span class=\"o\">=</span> <span class=\"n\">doc_word</span><span class=\"o\">.</span><span class=\"n\">word</span> <span class=\"o\">-</span> <span class=\"mi\">1</span>\n\n<span class=\"c1\">#convert to index of word counts per document</span>\n<span class=\"n\">doc_word_count</span>  <span class=\"o\">=</span> <span class=\"n\">doc_word</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">([</span><span class=\"s1\">'doc'</span><span class=\"p\">,</span><span class=\"s1\">'word'</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">to_frame</span><span class=\"p\">(</span><span class=\"s1\">'count'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">to_numpy</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">T</span>\n\n<span class=\"c1\">#convert to sparse matrix</span>\n<span class=\"n\">sparse_word_doc_matrix</span> <span class=\"o\">=</span> <span class=\"n\">csr_array</span><span class=\"p\">((</span><span class=\"n\">doc_word_count</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">],(</span><span class=\"n\">doc_word_count</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span><span class=\"n\">doc_word_count</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])),</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"n\">encoded_docs</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">dictionary</span><span class=\"p\">)),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"nb\">float</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">T</span>\n\n<span class=\"c1\">#visualize sparse matrix</span>\n<span class=\"n\">fig</span> <span class=\"o\">=</span> <span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">15</span><span class=\"p\">,</span><span class=\"mi\">15</span><span class=\"p\">))</span>\n<span class=\"n\">sparse_word_doc_matrix_visualization</span> <span class=\"o\">=</span> <span class=\"n\">fig</span><span class=\"o\">.</span><span class=\"n\">add_subplot</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">sparse_word_doc_matrix_visualization</span><span class=\"o\">.</span><span class=\"n\">spy</span><span class=\"p\">(</span><span class=\"n\">sparse_word_doc_matrix</span><span class=\"p\">,</span> <span class=\"n\">markersize</span><span class=\"o\">=</span><span class=\"mf\">0.007</span><span class=\"p\">,</span> <span class=\"n\">aspect</span> <span class=\"o\">=</span> <span class=\"s1\">'auto'</span><span class=\"p\">)</span>\n\n<span class=\"o\">%</span><span class=\"k\">store</span> sparse_word_doc_matrix\n<span class=\"o\">%</span><span class=\"k\">store</span> dictionary\n<span class=\"o\">%</span><span class=\"k\">store</span> dictionary_lookup\n</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\"> </div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<p>The visualization below shows the words (y-axis) and the documents (x-axis) they are in.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\"> </div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://using-namespace-system.github.io/media/posts/2/sparse_word_doc_matrix.png\" alt=\"\" width=\"1244\" height=\"1221\" sizes=\"100vw\" srcset=\"https://using-namespace-system.github.io/media/posts/2/responsive/sparse_word_doc_matrix-xs.png 300w ,https://using-namespace-system.github.io/media/posts/2/responsive/sparse_word_doc_matrix-sm.png 480w ,https://using-namespace-system.github.io/media/posts/2/responsive/sparse_word_doc_matrix-md.png 768w ,https://using-namespace-system.github.io/media/posts/2/responsive/sparse_word_doc_matrix-lg.png 1024w ,https://using-namespace-system.github.io/media/posts/2/responsive/sparse_word_doc_matrix-xl.png 1360w ,https://using-namespace-system.github.io/media/posts/2/responsive/sparse_word_doc_matrix-2xl.png 1600w\"></figure>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\"> </div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput\" data-mime-type=\"text/markdown\">\n<p>The words that occur together often in the corpus also, as word vectors, are closer together in this 1200000 dimensional vector space. This is demonstrated in the table below.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell jp-CodeCell jp-Notebook-cell\">\n<div class=\"jp-Cell-inputWrapper\" tabindex=\"0\">\n<div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"> </div>\n<div class=\"jp-InputArea jp-Cell-inputArea\">\n<div class=\"jp-InputPrompt jp-InputArea-prompt\">In [ ]:</div>\n<div class=\"jp-CodeMirrorEditor jp-Editor jp-InputArea-editor\" data-type=\"inline\">\n<div class=\"cm-editor cm-s-jupyter\">\n<div class=\"highlight hl-ipython3\">\n<pre><span class=\"c1\">#approximating cosine similarity with dot product of the term document matrix and its transform</span>\n\n<span class=\"n\">similarity_matrix</span>  <span class=\"o\">=</span> <span class=\"n\">sparse_word_doc_matrix</span> <span class=\"o\">@</span> <span class=\"n\">sparse_word_doc_matrix</span><span class=\"o\">.</span><span class=\"n\">T</span>\n\n<span class=\"c1\">#displaying slice of matrix with highest similarity scores</span>\n\n<span class=\"n\">similarity_matrix_compressed</span> <span class=\"o\">=</span> <span class=\"n\">similarity_matrix</span><span class=\"p\">[(</span><span class=\"o\">-</span><span class=\"n\">similarity_matrix</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">axis</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">argsort</span><span class=\"p\">()[:</span><span class=\"mi\">20</span><span class=\"p\">]]</span><span class=\"o\">.</span><span class=\"n\">toarray</span><span class=\"p\">()</span>\n\n<span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">((</span><span class=\"o\">-</span><span class=\"n\">similarity_matrix_compressed</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">argsort</span><span class=\"p\">(</span><span class=\"n\">axis</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">)[:</span><span class=\"mi\">20</span><span class=\"p\">,:</span><span class=\"mi\">20</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">T</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">applymap</span><span class=\"p\">(</span><span class=\"n\">dictionary_lookup</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">)</span>\n</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"jp-Cell-outputWrapper\">\n<div class=\"jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser\"> </div>\n<div class=\"jp-OutputArea jp-Cell-outputArea\">\n<div class=\"jp-OutputArea-child jp-OutputArea-executeResult\">\n<div class=\"jp-OutputPrompt jp-OutputArea-prompt\">Out[ ]:</div>\n<div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult\" tabindex=\"0\" data-mime-type=\"text/html\">\n<div>\n<table class=\"dataframe\" border=\"1\">\n<thead>\n<tr style=\"text-align: right;\">\n<th> </th>\n<th>0</th>\n<th>1</th>\n<th>2</th>\n<th>3</th>\n<th>4</th>\n<th>5</th>\n<th>6</th>\n<th>7</th>\n<th>8</th>\n<th>9</th>\n<th>10</th>\n<th>11</th>\n<th>12</th>\n<th>13</th>\n<th>14</th>\n<th>15</th>\n<th>16</th>\n<th>17</th>\n<th>18</th>\n<th>19</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>police</td>\n<td>new</td>\n<td>man</td>\n<td>says</td>\n<td>court</td>\n<td>nsw</td>\n<td>australia</td>\n<td>govt</td>\n<td>council</td>\n<td>fire</td>\n<td>australian</td>\n<td>qld</td>\n<td>sydney</td>\n<td>plan</td>\n<td>death</td>\n<td>water</td>\n<td>health</td>\n<td>crash</td>\n<td>back</td>\n<td>coast</td>\n</tr>\n<tr>\n<th>1</th>\n<td>man</td>\n<td>zealand</td>\n<td>charged</td>\n<td>govt</td>\n<td>man</td>\n<td>police</td>\n<td>day</td>\n<td>urged</td>\n<td>plan</td>\n<td>house</td>\n<td>open</td>\n<td>north</td>\n<td>man</td>\n<td>council</td>\n<td>police</td>\n<td>plan</td>\n<td>mental</td>\n<td>fatal</td>\n<td>hits</td>\n<td>gold</td>\n</tr>\n<tr>\n<th>2</th>\n<td>investigate</td>\n<td>laws</td>\n<td>police</td>\n<td>minister</td>\n<td>accused</td>\n<td>rural</td>\n<td>south</td>\n<td>nsw</td>\n<td>new</td>\n<td>crews</td>\n<td>market</td>\n<td>govt</td>\n<td>police</td>\n<td>water</td>\n<td>man</td>\n<td>restrictions</td>\n<td>service</td>\n<td>car</td>\n<td>bounce</td>\n<td>north</td>\n</tr>\n<tr>\n<th>3</th>\n<td>probe</td>\n<td>police</td>\n<td>court</td>\n<td>trump</td>\n<td>face</td>\n<td>govt</td>\n<td>coronavirus</td>\n<td>qld</td>\n<td>considers</td>\n<td>police</td>\n<td>dollar</td>\n<td>rural</td>\n<td>hobart</td>\n<td>govt</td>\n<td>toll</td>\n<td>council</td>\n<td>minister</td>\n<td>plane</td>\n<td>fight</td>\n<td>sunshine</td>\n</tr>\n<tr>\n<th>4</th>\n<td>missing</td>\n<td>cases</td>\n<td>murder</td>\n<td>new</td>\n<td>told</td>\n<td>country</td>\n<td>new</td>\n<td>vic</td>\n<td>water</td>\n<td>man</td>\n<td>south</td>\n<td>central</td>\n<td>western</td>\n<td>new</td>\n<td>inquest</td>\n<td>supply</td>\n<td>new</td>\n<td>dies</td>\n<td>track</td>\n<td>nsw</td>\n</tr>\n<tr>\n<th>5</th>\n<td>search</td>\n<td>australia</td>\n<td>jailed</td>\n<td>australia</td>\n<td>faces</td>\n<td>hour</td>\n<td>live</td>\n<td>says</td>\n<td>land</td>\n<td>threat</td>\n<td>year</td>\n<td>police</td>\n<td>charged</td>\n<td>basin</td>\n<td>charged</td>\n<td>govt</td>\n<td>services</td>\n<td>killed</td>\n<td>plan</td>\n<td>south</td>\n</tr>\n<tr>\n<th>6</th>\n<td>car</td>\n<td>york</td>\n<td>dies</td>\n<td>labor</td>\n<td>murder</td>\n<td>coast</td>\n<td>test</td>\n<td>plan</td>\n<td>seeks</td>\n<td>govt</td>\n<td>share</td>\n<td>health</td>\n<td>nsw</td>\n<td>backs</td>\n<td>court</td>\n<td>murray</td>\n<td>qld</td>\n<td>police</td>\n<td>court</td>\n<td>west</td>\n</tr>\n<tr>\n<th>7</th>\n<td>death</td>\n<td>council</td>\n<td>missing</td>\n<td>union</td>\n<td>high</td>\n<td>new</td>\n<td>india</td>\n<td>local</td>\n<td>says</td>\n<td>destroys</td>\n<td>new</td>\n<td>new</td>\n<td>morning</td>\n<td>murray</td>\n<td>rises</td>\n<td>new</td>\n<td>indigenous</td>\n<td>man</td>\n<td>urged</td>\n<td>police</td>\n</tr>\n<tr>\n<th>8</th>\n<td>officer</td>\n<td>year</td>\n<td>accused</td>\n<td>could</td>\n<td>front</td>\n<td>coronavirus</td>\n<td>world</td>\n<td>new</td>\n<td>plans</td>\n<td>nsw</td>\n<td>china</td>\n<td>government</td>\n<td>briefing</td>\n<td>group</td>\n<td>probe</td>\n<td>use</td>\n<td>funding</td>\n<td>driver</td>\n<td>get</td>\n<td>mid</td>\n</tr>\n<tr>\n<th>9</th>\n<td>hunt</td>\n<td>nsw</td>\n<td>guilty</td>\n<td>government</td>\n<td>hears</td>\n<td>government</td>\n<td>cup</td>\n<td>fed</td>\n<td>city</td>\n<td>school</td>\n<td>first</td>\n<td>south</td>\n<td>airport</td>\n<td>says</td>\n<td>woman</td>\n<td>irrigators</td>\n<td>says</td>\n<td>road</td>\n<td>says</td>\n<td>man</td>\n</tr>\n<tr>\n<th>10</th>\n<td>crash</td>\n<td>coronavirus</td>\n<td>car</td>\n<td>council</td>\n<td>case</td>\n<td>covid</td>\n<td>says</td>\n<td>funding</td>\n<td>backs</td>\n<td>suspicious</td>\n<td>shares</td>\n<td>election</td>\n<td>fire</td>\n<td>housing</td>\n<td>coroner</td>\n<td>says</td>\n<td>system</td>\n<td>two</td>\n<td>govt</td>\n<td>central</td>\n</tr>\n<tr>\n<th>11</th>\n<td>arrest</td>\n<td>south</td>\n<td>arrested</td>\n<td>opposition</td>\n<td>charges</td>\n<td>north</td>\n<td>cricket</td>\n<td>funds</td>\n<td>rejects</td>\n<td>factory</td>\n<td>man</td>\n<td>country</td>\n<td>new</td>\n<td>health</td>\n<td>investigate</td>\n<td>nsw</td>\n<td>govt</td>\n<td>highway</td>\n<td>australia</td>\n<td>east</td>\n</tr>\n<tr>\n<th>12</th>\n<td>murder</td>\n<td>hospital</td>\n<td>death</td>\n<td>report</td>\n<td>supreme</td>\n<td>cases</td>\n<td>china</td>\n<td>act</td>\n<td>urged</td>\n<td>service</td>\n<td>says</td>\n<td>western</td>\n<td>harbour</td>\n<td>government</td>\n<td>suspicious</td>\n<td>residents</td>\n<td>workers</td>\n<td>injured</td>\n<td>work</td>\n<td>cyclone</td>\n</tr>\n<tr>\n<th>13</th>\n<td>shooting</td>\n<td>centre</td>\n<td>crash</td>\n<td>wont</td>\n<td>alleged</td>\n<td>sydney</td>\n<td>covid</td>\n<td>defends</td>\n<td>rise</td>\n<td>home</td>\n<td>wins</td>\n<td>water</td>\n<td>shooting</td>\n<td>public</td>\n<td>penalty</td>\n<td>urged</td>\n<td>hospital</td>\n<td>dead</td>\n<td>win</td>\n<td>council</td>\n</tr>\n<tr>\n<th>14</th>\n<td>say</td>\n<td>years</td>\n<td>stabbing</td>\n<td>group</td>\n<td>appeal</td>\n<td>premier</td>\n<td>first</td>\n<td>water</td>\n<td>rates</td>\n<td>sydney</td>\n<td>chinese</td>\n<td>outback</td>\n<td>south</td>\n<td>rejects</td>\n<td>baby</td>\n<td>qld</td>\n<td>care</td>\n<td>truck</td>\n<td>new</td>\n<td>qld</td>\n</tr>\n<tr>\n<th>15</th>\n<td>seek</td>\n<td>says</td>\n<td>found</td>\n<td>expert</td>\n<td>police</td>\n<td>drought</td>\n<td>western</td>\n<td>accused</td>\n<td>mayor</td>\n<td>residents</td>\n<td>team</td>\n<td>says</td>\n<td>melbourne</td>\n<td>back</td>\n<td>murder</td>\n<td>farmers</td>\n<td>nsw</td>\n<td>bus</td>\n<td>school</td>\n<td>new</td>\n</tr>\n<tr>\n<th>16</th>\n<td>nsw</td>\n<td>home</td>\n<td>attack</td>\n<td>must</td>\n<td>sex</td>\n<td>fire</td>\n<td>zealand</td>\n<td>federal</td>\n<td>rate</td>\n<td>season</td>\n<td>killed</td>\n<td>man</td>\n<td>league</td>\n<td>opposition</td>\n<td>custody</td>\n<td>pipeline</td>\n<td>rural</td>\n<td>woman</td>\n<td>police</td>\n<td>sun</td>\n</tr>\n<tr>\n<th>17</th>\n<td>fatal</td>\n<td>govt</td>\n<td>assault</td>\n<td>health</td>\n<td>death</td>\n<td>election</td>\n<td>news</td>\n<td>fire</td>\n<td>development</td>\n<td>new</td>\n<td>government</td>\n<td>hour</td>\n<td>woman</td>\n<td>management</td>\n<td>guilty</td>\n<td>price</td>\n<td>boost</td>\n<td>probe</td>\n<td>bring</td>\n<td>found</td>\n</tr>\n<tr>\n<th>18</th>\n<td>new</td>\n<td>deal</td>\n<td>child</td>\n<td>police</td>\n<td>woman</td>\n<td>farmers</td>\n<td>england</td>\n<td>rejects</td>\n<td>budget</td>\n<td>ban</td>\n<td>day</td>\n<td>far</td>\n<td>siege</td>\n<td>labor</td>\n<td>family</td>\n<td>bans</td>\n<td>report</td>\n<td>pilot</td>\n<td>hit</td>\n<td>afl</td>\n</tr>\n<tr>\n<th>19</th>\n<td>drug</td>\n<td>covid</td>\n<td>killed</td>\n<td>chief</td>\n<td>drug</td>\n<td>west</td>\n<td>one</td>\n<td>boost</td>\n<td>govt</td>\n<td>danger</td>\n<td>coronavirus</td>\n<td>coast</td>\n<td>found</td>\n<td>nsw</td>\n<td>driver</td>\n<td>boost</td>\n<td>plan</td>\n<td>victim</td>\n<td>pay</td>\n<td>missing</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</main>",
            "author": {
                "name": "Brian Recktenwall-Calvet"
            },
            "tags": [
            ],
            "date_published": "2024-01-08T20:53:22-05:00",
            "date_modified": "2024-01-08T21:03:37-05:00"
        }
    ]
}
